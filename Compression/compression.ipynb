{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal and Image Processing (SIP_SS23)\n",
    "\n",
    "### Research Group Neuroinformatics, Faculty of Computer Science,\n",
    "### University of Vienna\n",
    "\n",
    "\n",
    "###  Huffman coding\n",
    "\n",
    "Lecturer: Prof. Moritz GROSSE-WENTRUP\n",
    "\n",
    "Tutorial by: Sadiq A. ADEDAYO <sadiq.adedayo@univie.ac.at> <br> \n",
    "$\\quad\\quad\\quad\\quad$ Jakob PRAGER <jakob.prager@univie.ac.at>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use huffman.py from moodle\n",
    "import numpy as np\n",
    "from huffman import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a string text with characters, each with known prior probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Fischers Fritz fischt frische Fische.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a function to calculate the frequency of each character in the text and save it in a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_cnt_func = lambda string: dict((char, string.count(char)) for char in set(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_dict = char_cnt_func(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we claculate the probability of each character and give it to the function \"huffman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0.02702702702702703,\n",
       " 'z': 0.02702702702702703,\n",
       " 'f': 0.05405405405405406,\n",
       " 't': 0.05405405405405406,\n",
       " 'e': 0.08108108108108109,\n",
       " 'F': 0.08108108108108109,\n",
       " 'r': 0.08108108108108109,\n",
       " 'c': 0.10810810810810811,\n",
       " ' ': 0.10810810810810811,\n",
       " 'h': 0.10810810810810811,\n",
       " 's': 0.13513513513513514,\n",
       " 'i': 0.13513513513513514}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_char = sum(cnt_dict.values())\n",
    "char_prob = {char: cnt_dict[char] / n_char for char in sorted(cnt_dict, key=cnt_dict.get)}\n",
    "char_prob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the huffman tree\n",
    "\n",
    "We create a function that follows the algorithm shown in class and constructs the huffman tree. \n",
    "\n",
    "It follows this pseudocode:\n",
    "\n",
    "function huffman(probability table): <br>\n",
    "• 1. Convergence? I.e., only one pair of string is left in the table . à Assign 0 and 1. <br>\n",
    "• 2. Find the pair of strings with lower probability, e.g., s_1 and s_2 <br>\n",
    "• 3. Merge them into one new string and compute the corresponding probability, i.e., s_new = s_1 + s_2 <br>\n",
    "• 4. Update the table with new string s_new <br>\n",
    "• 5. Further merge this new table until convergence (I.e., repeat 1-4) <br>\n",
    "• 6. Retrieve the huffman code for the new string s_new <br>\n",
    "• 7. Append 0 and 1 to the code for s_new, which is the huffman code for s_1 and s_2 respectively. <br>\n",
    "• return huffman code of this probability table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman(str_dict):\n",
    "\n",
    "    # str_dict = {string: probability}\n",
    "    assert abs(sum(str_dict.values())-1.0) < 1e-6,  \"The sum of probablities is not equal to 1.\"\n",
    "\n",
    "    assert len(str_dict) >= 2, \"The table contains less than two strings.\"\n",
    "    \n",
    "    # 1. Convergence?\n",
    "    if len(str_dict) == 2:\n",
    "        return dict(zip(str_dict.keys(), ['0', '1']))\n",
    "\n",
    "    merged_str_dict = str_dict.copy()\n",
    "\n",
    "    # 2. Find the pair of string with lowest probability\n",
    "    str_1, str_2 = sorted(str_dict, key=str_dict.get)[:2]\n",
    "    \n",
    "\n",
    "    # 3. Merge into new string and compute the probability\n",
    "    # 4. Update the dictionary (table)\n",
    "    prob_str_1 = merged_str_dict.pop(str_1)\n",
    "    prob_str_2 = merged_str_dict.pop(str_2)\n",
    "\n",
    "    merged_str = str_1 + str_2\n",
    "    merged_str_dict[merged_str] = prob_str_1 + prob_str_2\n",
    "\n",
    "    # 5&6. Further construct the huffman tree and retrieve the huffman code for\n",
    "    # this updated table\n",
    "\n",
    "    huffman_code = huffman(merged_str_dict)\n",
    "    \n",
    "    # 7. Append 0& 1 to the huffman code for the updated table\n",
    "    code_merged_str = huffman_code.pop(merged_str)\n",
    "    huffman_code[str_1] = code_merged_str + '0'\n",
    "    huffman_code[str_2] = code_merged_str + '1'\n",
    "\n",
    "    return huffman_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': '100',\n",
       " 's': '101',\n",
       " 'h': '010',\n",
       " ' ': '000',\n",
       " 'c': '001',\n",
       " 'e': '1110',\n",
       " 'r': '1111',\n",
       " 'F': '1101',\n",
       " 'f': '0110',\n",
       " 't': '0111',\n",
       " '.': '11000',\n",
       " 'z': '11001'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook = huffman(char_prob)\n",
    "codebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To encode a message we now only need to get the respective code for each character and add them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, codebook):\n",
    "    code = []\n",
    "    for x in text:\n",
    "        code.append(codebook[x])\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1101',\n",
       " '100',\n",
       " '101',\n",
       " '001',\n",
       " '010',\n",
       " '1110',\n",
       " '1111',\n",
       " '101',\n",
       " '000',\n",
       " '1101',\n",
       " '1111',\n",
       " '100',\n",
       " '0111',\n",
       " '11001',\n",
       " '000',\n",
       " '0110',\n",
       " '100',\n",
       " '101',\n",
       " '001',\n",
       " '010',\n",
       " '0111',\n",
       " '000',\n",
       " '0110',\n",
       " '1111',\n",
       " '100',\n",
       " '101',\n",
       " '001',\n",
       " '010',\n",
       " '1110',\n",
       " '000',\n",
       " '1101',\n",
       " '100',\n",
       " '101',\n",
       " '001',\n",
       " '010',\n",
       " '1110',\n",
       " '11000']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(text, codebook)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these three functions we can now encode every text we want"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
