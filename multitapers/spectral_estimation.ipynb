{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal and Image Processing (SIP_SS23)\n",
    "\n",
    "### Research Group Neuroinformatics, Faculty of Computer Science,\n",
    "### University of Vienna\n",
    "\n",
    "\n",
    "###  Spectral estimation methods Tutorial\n",
    "\n",
    "Lecturer: Prof. Moritz GROSSE-WENTRUP\n",
    "\n",
    "Tutorial by: Jakob PRAGER <jakob.prager@univie.ac.at>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aim: implement several spectral estimation methods and test them on data from a BCI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the lecture we already discussed that it is not trivial how we estimate spectrum of a signal. The naive approach is to just apply a FFT and make a periodogram. The Periodogram however is a poor estimate, as it is prone to a high variance and spectral leakage. There are several ways of adressing these issues. Today we will take a look at:\n",
    "##### 1. The naive approach <br>\n",
    "##### 2. Applying a window <br>\n",
    "##### 3. Bartlett's method <br>\n",
    "##### 4. Welch's method <br>\n",
    "##### 5. Multitapers <br>\n",
    "and test their performance on data that was gathered for Brain computer interfaces (BCIs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-05T12:25:01.687365Z",
     "end_time": "2024-01-05T12:25:01.707811Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17708/2786326820.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignal\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msio\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\signal\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    300\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mbsplines\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 302\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mfilter_design\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    303\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mfir_filter_design\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    304\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mltisys\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\signal\\filter_design.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpolynomial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpolynomial\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpolyvalfromroots\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mspecial\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfft\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msp_fft\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspecial\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcomb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_util\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfloat_factorial\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    399\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    400\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 401\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0m_minimize\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    402\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0m_root\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    403\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0m_root_scalar\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0m_trustregion_krylov\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_minimize_trust_krylov\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0m_trustregion_exact\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_minimize_trustregion_exact\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0m_trustregion_constr\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_minimize_trustregion_constr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;31m# constrained minimization\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mminimize_trustregion_constr\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_minimize_trustregion_constr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0m__all__\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'_minimize_trustregion_constr'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\minimize_trustregion_constr.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mOptimizeResult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_differentiable_functions\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mScalarFunction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mequality_constrained_sqp\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mequality_constrained_sqp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m from .canonical_constraint import (CanonicalConstraint,\n\u001B[0;32m     12\u001B[0m                                    initial_constraints_as_canonical)\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msparse\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0meye\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mspeye\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mprojections\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mprojections\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mqp_subproblem\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodified_dogleg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprojected_cg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbox_intersections\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36mget_code\u001B[1;34m(self, fullname)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36mpath_stats\u001B[1;34m(self, path)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36m_path_stat\u001B[1;34m(path)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SSVEP dataset\n",
    "SSVEP data is gatheres from subjects looking at flickering lights at different frequencies. By training a machine learning algorithm to detect the different frequencies one can build [visual keyboards](https://www.youtube.com/watch?app=desktop&v=gLVhplHu4Cs).\n",
    "The dataset consists of data gathered from one subject looking at 20 different frequencies. To use it with BCIs, the goal could be to train a machine learning classifier to detect if certain frequencies are present in the frequency spectrum. If we want to follow this approach, we should create a fairly accurate depiction of the frequencies in the signal. With this in mind we will now implement different spectral estimation methods."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#load data\n",
    "data_x = scipy.io.loadmat('tutorialdata.mat')['data']\n",
    "data_y = np.argmax(scipy.io.loadmat('tutorialdata.mat')['labels'], axis=1)\n",
    "\n",
    "# plot one sample signal of the SSVEP dataset\n",
    "plt.plot(data_x[20])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:23:57.874784Z",
     "end_time": "2024-01-05T12:24:08.839014Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. No window\n",
    "We don´t apply any spectral estimation methods and just create a periodogram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make an FFT of all samples, take the absolute and square it\n",
    "FFT_data_x = np.abs(np.fft.fft(data_x, axis = 1))**2\n",
    "\n",
    "# take only half (for consistensy reasons)\n",
    "FFT_data_x = FFT_data_x[:, :500]\n",
    "\n",
    "# plot spectrum\n",
    "fig , ax = plt.subplots(2,3, figsize = (15,8))\n",
    "ax[0,0].plot(FFT_data_x[4])\n",
    "ax[0, 0].set_title('No window')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:23:58.985837Z",
     "end_time": "2024-01-05T12:24:09.625220Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Using Windows\n",
    "Now we can try to apply windows to the samples before making a periodogram. We use the function \"scipy.signal.windows.get_window\" to create the windows. You can get all possible windows on:\n",
    "[link to scipy website](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.windows.get_window.html#scipy.signal.windows.get_window)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create windows. Feel free to play around with the type of window used.\n",
    "window = scipy.signal.get_window(\"hann\", 1000)\n",
    "\n",
    "\n",
    "# apply window to all samples\n",
    "windowed_data = data_x * window\n",
    "\n",
    "# create periodograms from windowed data\n",
    "FFT_windowed = np.abs(np.fft.fft(windowed_data, axis = 1))**2\n",
    "\n",
    "# take only half (for consistensy reasons)\n",
    "FFT_windowed = FFT_windowed[:, :500]\n",
    "\n",
    "# plot spectrum\n",
    "fig , ax = plt.subplots(2,3, figsize = (15,8))\n",
    "ax[0,0].plot(FFT_data_x[20])\n",
    "ax[0, 0].set_title('No window')\n",
    "ax[0,1].plot(FFT_windowed[20])\n",
    "ax[0, 1].set_title('Window')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:24:00.296460Z",
     "end_time": "2024-01-05T12:24:10.456715Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Bartlett's method\n",
    "\n",
    "Bartlett's method is a classical technique for estimating the power spectral density (PSD) of a random signal. It is based on dividing the signal into non-overlapping segments, applying a window function to each segment, and then averaging the squared magnitudes of the resulting Fourier transforms.\n",
    "\n",
    "\n",
    "Bartlett's method is particularly useful when dealing with stationary signals, and it provides a simple and intuitive way to estimate the frequency content of a signal.\n",
    "\n",
    "The PSD estimate using Bartlett's method is given by:\n",
    "\n",
    "$$\\hat{S_B}(w) \\quad = \\quad \\frac{1}{N_1} \\sum_{m = 1}^{N_1} \\frac{1}{N_2}\\Big(\\sum_{n=1}^{N_2} x[n+mN_2] \\cdot e^{-jwn}\\Big)^2$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for bartlett's method the variable is the split ratio. Feel free to play around with it and observe its performance.\n",
    "splitratio = 8\n",
    "\n",
    "# split data into equal sizes\n",
    "splitted_data =  np.array(np.split(data_x, 1000/splitratio, axis= 1))\n",
    "\n",
    "# make a FFT of each signal and square the absolute\n",
    "periodogram = np.abs(np.fft.fft(splitted_data, axis = 0))**2\n",
    "\n",
    "# take the mean of the periodograms of the split signals\n",
    "bartlett = np.mean(periodogram,axis=2).T[:,:int(1000/splitratio/2)]\n",
    "\n",
    "# plot spectra\n",
    "fig , ax = plt.subplots(2,3, figsize = (15,8))\n",
    "ax[0,0].plot(FFT_data_x[20])\n",
    "ax[0, 0].set_title('No window')\n",
    "ax[0,1].plot(FFT_windowed[20])\n",
    "ax[0, 1].set_title('Window')\n",
    "ax[0,2].plot(bartlett[20])\n",
    "ax[0, 2].set_title('Bartlett´s method')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:24:01.539028Z",
     "end_time": "2024-01-05T12:24:11.445138Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Welch´s method\n",
    "\n",
    "Welch's method is a spectral estimation technique that improves upon Bartlett's method by introducing overlapping segments. This helps reduce the variance of the spectral estimate compared to Bartlett's method, especially when dealing with short data sequences.\n",
    "\n",
    "Welch's method involves dividing the signal into overlapping segments, applying a window function to each segment, computing the periodograms, and then averaging them to obtain a smoother and more reliable estimate of the power spectral density."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# welch´s method is a bit more complicated to implement, so we create a function\n",
    "def welch_method_by_hand(x, y):\n",
    "    welch = []\n",
    "    for array in x:\n",
    "        splits = []\n",
    "        # Calculate the overlap size\n",
    "        overlap = y // 2\n",
    "        # Iterate to create n splits\n",
    "        for i in range(y):\n",
    "            start = i * (y - overlap)\n",
    "            end = start + y\n",
    "            # Ensure that the end index does not exceed the array length\n",
    "            if end > len(array):\n",
    "                break\n",
    "            splits.append(array[start:end])\n",
    "        #apply a window and create a periodogram\n",
    "        window = scipy.signal.get_window(\"hann\", y)\n",
    "        windowed_data = splits * window\n",
    "        periodogram = np.abs(np.fft.fft(windowed_data))**2\n",
    "\n",
    "        # take the mean of the periodograms of the split signals\n",
    "        welch.append(np.mean(periodogram,axis=0)[:split_length//2])\n",
    "\n",
    "    return welch\n",
    "\n",
    "# feel free to play around with the length of the splits\n",
    "split_length = 258\n",
    "Welch_FFT = welch_method_by_hand(data_x, split_length)\n",
    "\n",
    "# furthermore, we can test the scipy version of welchs method\n",
    "f, welch_FFT_2 = scipy.signal.welch(data_x, fs = 250)\n",
    "\n",
    "#plot all spectral estimations up to now\n",
    "fig , ax = plt.subplots(2,3, figsize = (15,8))\n",
    "ax[0,0].plot(FFT_data_x[20])\n",
    "ax[0, 0].set_title('No window')\n",
    "ax[0,1].plot(FFT_windowed[20])\n",
    "ax[0, 1].set_title('Window')\n",
    "ax[0,2].plot(bartlett[20])\n",
    "ax[0, 2].set_title('Bartlett´s method')\n",
    "ax[1,0].plot(Welch_FFT[20])\n",
    "ax[1, 0].set_title('Welch´s method')\n",
    "ax[1,1].plot(f,welch_FFT_2[20])\n",
    "ax[1, 1].set_title('Welch´s method (scipy)')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:24:03.909255Z",
     "end_time": "2024-01-05T12:24:12.596468Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Multitapers\n",
    "Multitaper is a time-frequency decomposition (spectral density estimation) method different from Short-Time Fourier Transform (STFT), Wavelet convolution, and Filter Hilbert methods. These three (3) methods, have similar procedures but with different applications. Multitaper differs from these three, but gives approximately the same result. Multitapers smooth signals over frequency and time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The aim is to design a set of optimal windows, such that we can smooth or average the  signal spectrum over a bandwidth of $2w_{s}$ which serves as the constraint for our optimization problem.\n",
    "\n",
    "$$\\big|X(w)\\big| \\quad = \\quad \\frac{1}{k} \\sum_{k = 1}^{K} \\Big|\\sum_{n=-\\frac{N}{2}}^{\\frac{N}{2}} w[k] \\cdot x[k] \\cdot e^{(-jwn)}\\Big|$$\n",
    "\n",
    "<br>\n",
    "Visual depiction of multitapers\n",
    "\n",
    "![picture.png](img\\picture.png)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# To compute the multitapers\n",
    "\n",
    "The expression is a simple multiplication of a window $w[n]$ with our signal $x[n]$; however, the window must be the same length as the original signal.\n",
    "\n",
    "$$x[n] \\cdot w[n]$$\n",
    "\n",
    "\n",
    "\n",
    "### Parameters\n",
    "\n",
    "Assuming a signal/window size $w$ ranging from $\\left[-\\frac{N}{2}, \\dots, \\frac{N}{2}\\right]$, The length of the signal/window is then given as `N+1`.\n",
    "\n",
    "$w_{s}$ is the allowable bandwidth/threshold at which the multitaper can smoothen our spectrum\n",
    "\n",
    "$A$ measures the energy concentration of the multitapers\n",
    "\n",
    "$$\\sum_{n=-\\frac{N}{2}}^{\\frac{N}{2}}\\sum_{m=-\\frac{N}{2}}^{\\frac{N}{2}} \\frac{2sin \\left(w_{s}(m - n\\right))}{m - n}$$\n",
    "\n",
    "Recall, the solution to the optimization problem is given as\n",
    "$$A.\\vec{w} = \\lambda^{'} \\vec{w}$$\n",
    "\n",
    "With matrix decomposition:\n",
    "$$\\vec{w^{T}}A\\vec{w} = \\lambda^{'}\\vec{w^{T}}\\vec{w} = \\lambda^{'}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let N be 1000 in this case\n",
    "\n",
    "N = 1000\n",
    "w_s = 0.01*np.pi  # here we selected an allowable threshold of 0.1, this will be tuned afterwards\n",
    "\n",
    "m = np.arange(N)\n",
    "n = np.arange(N)\n",
    "\n",
    "A = 2 * np.sin(w_s * (n[:,None] - m[None,:])) / (n[:,None] - m[None,:])\n",
    "\n",
    "np.fill_diagonal(A,2* w_s)\n",
    "plt.imshow(A)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:24:04.295250Z",
     "end_time": "2024-01-05T12:24:12.910148Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We filled the diagonals of $A$ with $2w_{s}$ because we encountered some zero division error every time n == m.\n",
    "\n",
    "To solve this, we need to fill it with the limit of the function as n approaches m using [$\\textbf{L'Hôpital's rule}$](https://en.wikipedia.org/wiki/L%27H%C3%B4pital%27s_rule).\n",
    "\n",
    "Recall from the lecture, we constrained our optimization function with $2w_{s}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute eigenvectors\n",
    "\n",
    "#### Hint: we use np.linalg.eigh(A) because it gives the eigenvectors sorted according to their respective eigenvalue\n",
    "\n",
    "The eigenvalue plot will enable us to determine the number of eigenvalues that will be useful for selecting eigenvectors (multitapers) for our use.\n",
    "\n",
    "We are only interested in those multitapers corresponding to eigenvalues with very high energy concentrations. In simple terms, selecting those eigenvectors means we only consider multitapers with the highest energy concentration.\n",
    "\n",
    "For the sake of demonstration, I defined a variable `count` as the number of eigenvalues selected and plotted them in red color.\n",
    "\n",
    "#### Note: You can toy around with the choice of `count`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eig_values, eig_vectors = np.linalg.eigh(A)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:24:06.169195Z",
     "end_time": "2024-01-05T12:24:15.051172Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count = 10\n",
    "\n",
    "# plot the number of eigenvalues selected and observe their values\n",
    "plt.scatter(range(N - count, N), np.log(np.abs(eig_values[-count:])), color='red')\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:24:06.409215Z",
     "end_time": "2024-01-05T12:24:15.253566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot eigen vecors\n",
    "for i in range(1,count+1):\n",
    "    plt.plot(eig_vectors[:,-i],label=f'eig vec {i}')\n",
    "    plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:24:06.913468Z",
     "end_time": "2024-01-05T12:24:15.727687Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the plot, we can see that the multitapers are orthogonal and mutually uncorrelated to one another. The first multitaper (with only the first eigenvector) looks precisely Gaussian, and the second one appears as a derivative of the first, and so on. These are not coincidences but rather show the orthogonality of the multitapers. All the individual orthogonal multitapers will then work together as a sequence. The aim is that each of these multitapers will capture or highlight different features in the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can check the efficiency of our selected number of multitapers by taking the Fourier Transform as described below. The efficiency is measured by how the overall multitaper approximates a rectangular window.\n",
    "\n",
    "$$|X(w)| = \\frac{1}{K} \\sum_{k = 1}^{K} \\Big|\\sum_{n=-\\frac{N}{2}}^{\\frac{N}{2}} w_k[n] \\cdot x[n] \\cdot e^{(-jwn)}\\Big|$$\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from scipy.fft import fft, fftfreq, ifft\n",
    "FFTs = []\n",
    "\n",
    "# loop over eigenvectors to multiplicate them with the data\n",
    "# you can change the number of tapers used by changing the range\n",
    "for x in range(1,10):\n",
    "     FFTs.append(np.abs(np.fft.fft(data_x*eig_vectors[:,-x],axis=1)))\n",
    "FFTs = np.array(FFTs)\n",
    "\n",
    "# take the mean of all tapers\n",
    "tapered_FFT = np.mean(FFTs, axis=0)\n",
    "\n",
    "# take only half for consistency reasons\n",
    "tapered_FFT = tapered_FFT[:,:500]\n",
    "\n",
    "# plot all spectral estimations up to now\n",
    "fig , ax = plt.subplots(2,3, figsize = (15,8))\n",
    "ax[0,0].plot(FFT_data_x[20])\n",
    "ax[0, 0].set_title('No window')\n",
    "ax[0,1].plot(FFT_windowed[20])\n",
    "ax[0, 1].set_title('Window')\n",
    "ax[0,2].plot(bartlett[20])\n",
    "ax[0, 2].set_title('Bartlett´s method')\n",
    "ax[1,0].plot(Welch_FFT[20])\n",
    "ax[1, 0].set_title('Welch´s method')\n",
    "ax[1,1].plot(f,welch_FFT_2[20])\n",
    "ax[1, 1].set_title('Welch´s method (scipy)')\n",
    "ax[1,2].plot(tapered_FFT[20])\n",
    "ax[1, 2].set_title('Multitapers')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:24:08.208411Z",
     "end_time": "2024-01-05T12:24:16.808682Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test performance of spectral estimation\n",
    "We can now train a support vector classifier (SVC) for each spectral estimation method and test how well it can predict unseen data.\n",
    "\n",
    "In this case we use a SVC for the sake of simplicity. While a CNN might perform better generally, we don´t need to achieve perfect classification accuracy but want to explore the differences between spectral estimation techniques."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a library to iterate over them\n",
    "methods = {\"No window\":FFT_data_x,\"Window\":FFT_windowed,\"multitapers\" :tapered_FFT,  'bartletts method' : bartlett, \"welchs method\" :Welch_FFT,\"welch(sicpy)\" :welch_FFT_2}\n",
    "\n",
    "#initialize figure for plotting\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Accuracy of SVC for different spectral estimation methods ')\n",
    "\n",
    "#iterate over all methods and train a SVC on the samples\n",
    "for method in methods:\n",
    "    # split data into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(methods[method], data_y, test_size=0.33, random_state=42)\n",
    "    # we scale the data and train a SVC\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "    pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "    score = pipe.set_params(svc__C=10).fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "    #print results\n",
    "    print((method, score))\n",
    "    #visualize results\n",
    "    plt.bar(method,score, width=0.5)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-05T12:24:08.624461Z",
     "end_time": "2024-01-05T12:24:17.143025Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "24517ad26bc3da5ed37c649f05b5fd045e419cb42354ac2ff28ca24d9bf97f39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
